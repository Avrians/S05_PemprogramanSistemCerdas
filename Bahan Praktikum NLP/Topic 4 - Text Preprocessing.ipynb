{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EYhaY5qlWYIL"},"source":["# Mount drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SC5epXgFl3CR","executionInfo":{"status":"ok","timestamp":1666104530062,"user_tz":-420,"elapsed":29575,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"b4708254-a682-4240-9434-aeb7e9ab9c8d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#pindah ke direktori yang digunakan\n","%cd '/content/drive/MyDrive/1 Pengajaran Pendidikan/Kuliah/SI_BISAAI_NLP'"],"metadata":{"id":"UFHSFOhLL2tD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666104530063,"user_tz":-420,"elapsed":10,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"56dc4473-cd98-4510-fc8c-6abae642dedd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/drive/MyDrive/1 Pengajaran Pendidikan/Kuliah/SI_BISAAI_NLP'\n","/content\n"]}]},{"cell_type":"markdown","metadata":{"id":"pzRPywPqvbpe"},"source":["#1.Import Library\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"IFpeWdQO62se","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666104535672,"user_tz":-420,"elapsed":5615,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"48609fce-3566-4d25-82a1-283e461bfc79"},"source":[" ! pip install dataframe-image"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting dataframe-image\n","  Downloading dataframe_image-0.1.3-py3-none-any.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 14.7 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.7/dist-packages (from dataframe-image) (3.2.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from dataframe-image) (21.3)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.7/dist-packages (from dataframe-image) (5.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from dataframe-image) (3.8.3)\n","Requirement already satisfied: mistune in /usr/local/lib/python3.7/dist-packages (from dataframe-image) (0.8.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from dataframe-image) (1.3.5)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from dataframe-image) (4.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from dataframe-image) (2.23.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->dataframe-image) (3.0.9)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->dataframe-image) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->dataframe-image) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->dataframe-image) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1->dataframe-image) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.1->dataframe-image) (4.1.1)\n","Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (2.11.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (1.5.0)\n","Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (5.7.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (5.1.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (5.0.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (0.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (0.6.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (0.7.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (2.6.1)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert>=5->dataframe-image) (4.11.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert>=5->dataframe-image) (2.0.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert>=5->dataframe-image) (4.3.3)\n","Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert>=5->dataframe-image) (5.0.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4->nbconvert>=5->dataframe-image) (2.16.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat>=4.4->nbconvert>=5->dataframe-image) (3.9.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=5->dataframe-image) (22.1.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=5->dataframe-image) (5.10.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.4->nbconvert>=5->dataframe-image) (0.18.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->dataframe-image) (2022.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1->dataframe-image) (1.15.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->dataframe-image) (6.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->dataframe-image) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->dataframe-image) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->dataframe-image) (0.13.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->dataframe-image) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->dataframe-image) (1.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->dataframe-image) (1.3.1)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->dataframe-image) (2.10)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=5->dataframe-image) (0.5.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->dataframe-image) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->dataframe-image) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->dataframe-image) (1.24.3)\n","Installing collected packages: dataframe-image\n","Successfully installed dataframe-image-0.1.3\n"]}]},{"cell_type":"code","metadata":{"id":"7uBcsL0kBoJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666104538660,"user_tz":-420,"elapsed":2996,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"243a4c33-3356-4b70-d3ab-dc0e328ba892"},"source":["!pip install varname"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting varname\n","  Downloading varname-0.10.0-py3-none-any.whl (22 kB)\n","Collecting executing<2.0,>=1.1\n","  Downloading executing-1.1.1-py2.py3-none-any.whl (22 kB)\n","Installing collected packages: executing, varname\n","Successfully installed executing-1.1.1 varname-0.10.0\n"]}]},{"cell_type":"code","metadata":{"id":"xUbsTDyZH73U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666104543256,"user_tz":-420,"elapsed":4638,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"d0019e01-6d90-4b14-b64c-38d031adc6d4"},"source":["!pip install keras-metrics"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras-metrics\n","  Downloading keras_metrics-1.1.0-py2.py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras-metrics) (2.9.0)\n","Installing collected packages: keras-metrics\n","Successfully installed keras-metrics-1.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"3kZUFQ0Dtk1X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666104545285,"user_tz":-420,"elapsed":2039,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"e1246e14-acb1-4dec-8fa7-18abf5ba2ffc"},"source":["!pip install h5py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"]}]},{"cell_type":"code","source":["pip install sastrawi"],"metadata":{"id":"4-k4rO-INRjf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666104547970,"user_tz":-420,"elapsed":2693,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"e7c1f7b9-53c1-47bf-f93f-3855213afabe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sastrawi\n","  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 11.9 MB/s \n","\u001b[?25hInstalling collected packages: sastrawi\n","Successfully installed sastrawi-1.0.1\n"]}]},{"cell_type":"code","metadata":{"id":"HI4ujUlnZah4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666104552517,"user_tz":-420,"elapsed":4559,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"19494969-6d2c-4ed1-bef9-3c6030958227"},"source":["import nltk\n","import pandas as pd\n","import re\n","import tensorflow as tf\n","import time\n","import multiprocessing\n","import io\n","import gensim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras_metrics as km\n","import pickle\n","import keras\n","\n","\n","from tensorflow import keras\n","from keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","#from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint\n","from keras.preprocessing.text import Tokenizer\n","from keras.models import Sequential\n","from keras.layers import Embedding\n","from keras.layers import Dense, Activation, Embedding, LSTM, Bidirectional, Dropout, GRU\n","from keras import regularizers\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import load_model\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn import metrics\n","from nltk.tokenize import TweetTokenizer\n","from collections import defaultdict\n","from datetime import timedelta\n","from gensim.models import word2vec\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n","from sklearn.feature_extraction.text import CountVectorizer\n","from varname import nameof\n","\n","\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"markdown","metadata":{"id":"qtyarzfKc1DO"},"source":["#2.Load Data"]},{"cell_type":"code","metadata":{"id":"zg_Jvs3Qa3pq","colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"status":"error","timestamp":1666104553827,"user_tz":-420,"elapsed":1327,"user":{"displayName":"Ajis Dzalparo","userId":"07652867279345663708"}},"outputId":"4e16b08d-13cd-496a-9490-b1e03be6d9df"},"source":["#simpan path dataset\n","path_data = \"ulasan-20.csv\"\n","\n","#read dataset\n","data_dataset = pd.read_csv(path_data, sep=\",\", header=[0], encoding=\"UTF-8\")\n","print(data_dataset)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-cb41cdb12968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#read dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ulasan-20.csv'"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"3ezMMQQv3KnJ"}},{"cell_type":"markdown","metadata":{"id":"fHd8zoL5ePma"},"source":["#3.Implementasi Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"gNzxbK5i0Pcu"},"source":["##3.1. Casefolding"]},{"cell_type":"code","metadata":{"id":"LcNrqHr50MeU"},"source":["#mengambil data ulasan\n","data_content = data_dataset ['ulasan']\n","print(data_content[:4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALc2jvPU0Ueb"},"source":["#casefolding\n","data_casefolding = data_content.str.lower()\n","data_casefolding.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8A0nfLDO0Xgy"},"source":["##3.2. Filtering/Removing\n","\n","```\n","# This is formatted as code\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"pVsCbmmq0cuS"},"source":["#filtering\n","\n","#url\n","filtering_url = [re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\n","\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))\\n''',\n"," \" \", tweet) for tweet in data_casefolding]\n","#cont\n","filtering_cont = [re.sub(r'\\(cont\\)',\" \", tweet)for tweet in filtering_url]\n","#punctuatuion\n","filtering_punctuation = [re.sub(r'[!\"”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~]', ' ', tweet) for tweet in filtering_cont]  \n","#hapus simbol'[!#?,.:\";@()-_/\\']'\n","#  hapus tagger\n","filtering_tagger = [re.sub(r'#([^\\s]+)', '', tweet) for tweet in filtering_punctuation]\n","#numeric\n","filtering_numeric = [re.sub(r'\\d+', ' ', tweet) for tweet in filtering_tagger]\n","\n","# # filtering RT , @ dan #\n","# fungsi_clen_rt = lambda x: re.compile('\\#').sub('', re.compile('rt @').sub('@', x, count=1).strip())\n","# clean = [fungsi_clen_rt for tweet in filtering_numeric]\n","\n","data_filtering = pd.Series(filtering_numeric)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZ7vaeLzXE8_"},"source":["data_filtering"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ts2lHtue0kAk"},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["#tokenization\n","data_tokens = [word_tokenize(line) for line in data_filtering]\n","print(data_tokens)"],"metadata":{"id":"xIuQ19zbVci4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UZk9kLGa0sSB"},"source":["##3.4. Konversi Slangword"]},{"cell_type":"code","metadata":{"id":"LXnSpBqGeGyb"},"source":[" "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yp6NXGRerCK4"},"source":["## 3.5. Stopword Removal"]},{"cell_type":"code","metadata":{"id":"ogP3tGEHggHJ"},"source":["nltk.download('stopwords')\n","default_stop_words = nltk.corpus.stopwords.words('indonesian')\n","stopwords = set(default_stop_words)\n","\n","def removeStopWords(line, stopwords):\n","  words = []\n","  for word in line:  \n","    word=str(word)\n","    word = word.strip()\n","    if word not in stopwords and word != \"\" and word != \"&\":\n","      words.append(word)\n","\n","  return words\n","data_notstopword = [removeStopWords(line,stopwords) for line in data_formal]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4-E38TJ3mwbz"},"source":["print(pd.DataFrame(default_stop_words)[:10])"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vTjsGkv-052P"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPbyKfzzeVwC"},"source":["len(data_notstopword)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f86xvFd6hpLU"},"source":["data_notstopword"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##3.6. Stemming"],"metadata":{"id":"oyvZ6b9HTlDj"}},{"cell_type":"code","source":[" #ini perlu/tidak perlu diubah karena dianggap sastrawi sebagai imbuhan i\n","white_list = [\"bali\"]\n","factory = StemmerFactory()\n","ind_stemmer = factory.create_stemmer()\n","def stemmer(line):\n","    temp = list()\n","    for word in line:\n","      if(word not in white_list):\n","        word = ind_stemmer.stem(word)\n","      if(len(word)>3):\n","        temp.append(word)\n","    return temp\n","\n","reviews = [stemmer (line) for line in data_notstopword]\n","print(reviews)"],"metadata":{"id":"5tJ02fxlTqXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#coba ganti ke pandas\n","data_bersih = pd.Series(reviews)"],"metadata":{"id":"KAlcq4DW0Rdk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#coba simpan ke csv\n","data_bersih.to_csv('databersih.csv')"],"metadata":{"id":"5D5pK2wz0vYZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OC8PCY0TPvqq"},"source":["#4.Konversi Kalimat"]},{"cell_type":"code","metadata":{"id":"TSh1qQHv5RNs"},"source":["#Pembuatan Kamus kata\n","t  = Tokenizer()\n","fit_text = reviews\n","t.fit_on_texts(fit_text)\n","\n","#Pembuatan Id masing-masing kata\n","sequences = t.texts_to_sequences(reviews)\n","\n","#hapus duplikat kata yang muncul\n","list_set_sequence = [list(dict.fromkeys(seq)) for seq in sequences]\n","\n","#mencari max length sequence\n","def FindMaxLength(lst): \n","    maxList = max((x) for x in lst) \n","    maxLength = max(len(x) for x in lst ) \n","    return maxList, maxLength \n","      \n","# Driver Code \n","max_seq, max_length_seq = FindMaxLength(list_set_sequence)\n","jumlah_index = len(t.word_index) +1\n","\n","print('jumlah index : ',jumlah_index,'\\n')\n","print('word_index : ',t.word_index,'\\n')\n","print('index kalimat asli     : ', sequences,'\\n')\n","print('kalimat tanpa duplikat : ',list_set_sequence,'\\n')\n","print('panjang max kalimat : ', max_length_seq,'kata','\\n')\n","# print('kalimat terpanjang setelah dihapus duplikat : ', max_seq,'\\n')\n","\n","count_word = [len(i) for i in list_set_sequence]\n","print('list panjang kalimat : ', count_word)\n","max_len_word = max(count_word)\n","print(max_len_word)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fthKUepm-jy5"},"source":["min_len_word=min(count_word)\n","print(min_len_word)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gmhGiED75YTA"},"source":["print (\"Original list is : \" + str(list_set_sequence[0])) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CjDkNf3sLWVh"},"source":["## 4.1. Padding"]},{"cell_type":"code","metadata":{"id":"uv3AMe9jRI6X"},"source":["#Padding\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","padding= pad_sequences([list(list_set_sequence[i]) for i in range(len(list_set_sequence))],\n","maxlen= max_len_word, padding='pre')\n","padding[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TOPIC 5 - FEATURE EXTRACTION"],"metadata":{"id":"BW9m46pFGlf_"}},{"cell_type":"markdown","source":["##Load Hasil Preprocessing & Join\n"],"metadata":{"id":"vr4yLHUAJ1-E"}},{"cell_type":"code","source":["\n","reviews2 = [\" \".join(r) for r in reviews]\n"],"metadata":{"id":"Wk_AgHOW5kDN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Convectorizer"],"metadata":{"id":"8LO7IzKDHKZ-"}},{"cell_type":"code","source":["vectorizer = CountVectorizer()\n","X_vec = vectorizer.fit_transform(reviews2)\n","print(vectorizer.vocabulary_ )\n","print(X_vec.todense())"],"metadata":{"id":"P1km8zVLIefP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Bag of Word "],"metadata":{"id":"k3GP9hxFIukP"}},{"cell_type":"markdown","source":["### Building the vocabulary"],"metadata":{"id":"aepU50ltGuDk"}},{"cell_type":"code","source":["set_of_words = set()\n","for sentence in reviews2:\n","    for word in sentence.split():\n","        set_of_words.add(word)\n","vocab = list(set_of_words)\n","print(vocab)"],"metadata":{"id":"fTFYibFf-L0H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Fetching the position of each word in the vocabulary"],"metadata":{"id":"fncY1pgEHDKT"}},{"cell_type":"code","source":["position = {}\n","for i, token in enumerate(vocab):\n","    position[token] = i\n","print(position)"],"metadata":{"id":"HyVNyi3a-nsl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating a matrix to hold the Bag of Words representation"],"metadata":{"id":"B5z4qAC7I7VZ"}},{"cell_type":"code","source":["bow_matrix = np.zeros((len(reviews2), len(vocab)))"],"metadata":{"id":"IUJNpZPAJD7n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, preprocessed_sentence in enumerate(reviews2):\n","    for token in preprocessed_sentence.split():   \n","        bow_matrix[i][position[token]] = bow_matrix[i][position[token]] + 1"],"metadata":{"id":"J7AtFQ8UJE1V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bow_matrix"],"metadata":{"id":"8IwWJTuLJJhe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##N-gram"],"metadata":{"id":"k8sypG_MJcrv"}},{"cell_type":"markdown","source":["### Unigram, Bigram, Trigram"],"metadata":{"id":"ZFImff-dKLFI"}},{"cell_type":"code","source":["vectorizer_ngram_range = CountVectorizer(analyzer='word', ngram_range=(1,3))\n","bow_matrix_ngram = vectorizer_ngram_range.fit_transform(reviews2)"],"metadata":{"id":"RMENUHcPSxK4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(vectorizer_ngram_range.get_feature_names())\n","print(bow_matrix_ngram.toarray())"],"metadata":{"id":"Rb6xin2JS3s3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Max_feature"],"metadata":{"id":"Q4fZOExeKZDL"}},{"cell_type":"code","source":["vectorizer_max_features = CountVectorizer(analyzer='word', ngram_range=(1,3), max_features = 100)\n","bow_matrix_max_features = vectorizer_max_features.fit_transform(reviews2)"],"metadata":{"id":"j7JxEDCVKgvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(vectorizer_max_features.get_feature_names())\n","print(bow_matrix_max_features.toarray())"],"metadata":{"id":"DPjEJYl_Ko96"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Max_df & Min_df"],"metadata":{"id":"1QJ3SXoSKq27"}},{"cell_type":"code","source":["vectorizer_max_min = CountVectorizer(analyzer='word', ngram_range=(1,3), max_df =3, min_df = 2)\n","bow_matrix_max_min = vectorizer_max_min.fit_transform(preprocessed_corpus)"],"metadata":{"id":"YYsy9kwuKvMD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(vectorizer_max_min.get_feature_names())\n","print(bow_matrix_max_min.toarray())"],"metadata":{"id":"hsMQc7moKxyQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TF-IDF"],"metadata":{"id":"BZyv-qWkK15k"}},{"cell_type":"code","source":["vectorizer = TfidfVectorizer()\n","tf_idf_matrix = vectorizer.fit_transform(preprocessed_corpus)"],"metadata":{"id":"_GUXbHQRK6E1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(vectorizer.get_feature_names())\n","print(tf_idf_matrix.toarray())\n","print(\"\\nThe shape of the TF-IDF matrix is: \", tf_idf_matrix.shape)"],"metadata":{"id":"6Y2aK8ZMK_gS"},"execution_count":null,"outputs":[]}]}