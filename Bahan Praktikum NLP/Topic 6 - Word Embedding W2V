{"cells":[{"cell_type":"markdown","source":["#1 Google Drive Access"],"metadata":{"id":"EzyIY7wjPWCQ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":810966,"status":"ok","timestamp":1664335413064,"user":{"displayName":"DWI INTAN AF'IDAH","userId":"02413713999392776136"},"user_tz":-420},"id":"sKtqyGVIg5Qg","outputId":"7840ef31-366e-4e9c-87e3-605245069343"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#2 Directory Folder"],"metadata":{"id":"wWHk7evMPcLd"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1664338363676,"user":{"displayName":"DWI INTAN AF'IDAH","userId":"02413713999392776136"},"user_tz":-420},"id":"vtxkWrZ7g8__","outputId":"65e6f123-e922-4643-9077-9c4bcf5ca0f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/1 Pengajaran Pendidikan/Kuliah/SI_BISAAI_NLP\n"]}],"source":["#move to working directory\n","%cd \"/content/drive/MyDrive/1 Pengajaran Pendidikan/Kuliah/SI_BISAAI_NLP\""]},{"cell_type":"markdown","source":["#3 Change idiwiki.xml to idiwiki.text"],"metadata":{"id":"ppbTtl5ZPpB7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8Uhc9eNDgrRl"},"outputs":[],"source":["from __future__ import print_function\n"," \n","# Ignore warnings dari gensim\n","import warnings\n","warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n"," \n","import logging\n","import os.path\n","import sys\n"," \n","from gensim.corpora import WikiCorpus\n"," \n","program = os.path.basename(sys.argv[0])\n","logger = logging.getLogger(program)\n"," \n","logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s')\n","logging.root.setLevel(level=logging.INFO)\n","logger.info(\"running %s\" % ' '.join(sys.argv))\n"," \n","namaFileInput = \"idwiki-latest-pages-articles.xml.bz2\"\n","namaFileOutput = \"idwiki.text\"\n"," \n","space = \" \"\n","i = 0\n"," \n","# Write file ke variabel namaFileOutput encoder utf-8\n","output = open(namaFileOutput, 'w', encoding='utf-8')\n"," \n","# lower=False: huruf kecil dan besar dibedakan\n","wiki = WikiCorpus(namaFileInput, lemmatize=False, dictionary={}, lower=False)\n","for text in wiki.get_texts():\n","    output.write(' '.join(text) + '\\n')\n","    i = i + 1\n","    if i % 10000 == 0:\n","        logger.info(\"Saved \" + str(i) + \" articles\")\n"," \n","output.close()\n","logger.info(\"Finished Saved \" + str(i) + \" articles\")"]},{"cell_type":"markdown","source":["#4 Create Model Word2Vec"],"metadata":{"id":"ADft22atPzpc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MThTB7cghG4M"},"outputs":[],"source":["import multiprocessing\n","import logging\n","import os.path\n","import sys\n","import multiprocessing\n","from gensim.models import Word2Vec\n","from gensim.models.word2vec import LineSentence\n"," \n","program = os.path.basename(sys.argv[0])\n","logger = logging.getLogger(program)\n"," \n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n","logging.root.setLevel(level=logging.INFO)\n","logger.info(\"running %s\" % ' '.join(sys.argv))\n"," \n","namaFileInput = \"idwiki.text\"\n","namaFileOutput = \"w2v_idwiki_sg_300_HS.model\"\n"," \n"," \n","# size 300 = 300 dimensi vektor, window 10 = 10 pengaruh kata disekitarnya, \n","#min_count 5 = kata-kata yang muncul < 5 kali akan dikeluarkan dari kosakata dan diabaikan selama pelatihan\n","#sg 0 = cbow / sg 1 = skip gram, hs=1---> hierarchical softmax/ ns 1 =negative sampling \n","model = Word2Vec(LineSentence(namaFileInput), size=300, window=10, min_count=5, sg=1, hs=1, workers=multiprocessing.cpu_count())\n"," \n","# trim unneeded model memory = use (much) less RAM\n","model.init_sims(replace=True)\n","model.wv.save_word2vec_format(namaFileOutput)"]},{"cell_type":"markdown","source":["#5 Load Model"],"metadata":{"id":"0JuIledwQBJF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"o23AvVbjFPoE"},"outputs":[],"source":["import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","import pickle\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","word_vectors = KeyedVectors.load_word2vec_format('w2v_idwiki_cbow_100_HS.model') \n"]},{"cell_type":"code","source":[],"metadata":{"id":"UI3mEJpFE_Bn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word_vectors.wv['bagus']"],"metadata":{"id":"xM2qs5RYt8yC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#6 Testing Word using Word2Vec Model"],"metadata":{"id":"xER5Xn9OQLUX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VTX12EvEQ3nZ"},"outputs":[],"source":["sim = word_vectors.wv.most_similar(\"Jakarta\")\n","print(\"10 kata terdekat dari Jakarta:{}\".format(sim))\n","sim = word_vectors.wv.most_similar(\"Bandung\")\n","print(\"10 kata terdekat dari Bandung:{}\".format(sim))\n","\n","sim = word_vectors.wv.similarity(\"Yogyakarta\", \"Surakarta\")\n","print(\"Kedekatan Yogyakarta-Surakarta: {}\".format(sim))\n","sim = word_vectors.wv.similarity(\"Yogyakarta\", \"Semarang\")\n","print(\"Kedekatan Yogyakarta-Semarang: {}\".format(sim))\n"," \n","sim = word_vectors.wv.most_similar_cosmul(positive=['minuman', 'rendang'], negative=['makanan'])\n","print(\"makanan-rendang, minuman-?: {}\".format(sim))\n","sim = word_vectors.wv.most_similar_cosmul(positive=['mobil', 'honda'], negative=['motor'])\n","print(\"motor-honda, mobil-?: {}\".format(sim))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U985AnJKQFiq"},"outputs":[],"source":["import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","import pickle\n","import numpy as np\n","from keras.preprocessing.text import Tokenizer as t\n","\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","w2v_layer = KeyedVectors.load_word2vec_format('w2v_wiki_sg.model')\n","\n","jumlah_index = 12048 \n","EMBEDDING_DIM=300 #diganti sesuai dimensi\n","vocabulary_size= jumlah_index  #min(len(word_index)+1,NUM_WORDS)\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in t.word_index.items():\n","    try:\n","        embedding_vector = w2v_layer[word]\n","        embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n","\n","del(w2v_layer)\n","\n","from keras.layers import Embedding\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3S_XiXnTUwZ"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}